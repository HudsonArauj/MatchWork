{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain (from -r requirements.txt (line 1))\n",
      "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-community (from -r requirements.txt (line 2))\n",
      "  Downloading langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting llama-parse (from -r requirements.txt (line 3))\n",
      "  Downloading llama_parse-0.5.13-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting fastembed (from -r requirements.txt (line 4))\n",
      "  Downloading fastembed-0.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting chromadb (from -r requirements.txt (line 5))\n",
      "  Downloading chromadb-0.5.18-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting python-dotenv (from -r requirements.txt (line 6))\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting langchain-groq (from -r requirements.txt (line 7))\n",
      "  Downloading langchain_groq-0.2.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting chainlit (from -r requirements.txt (line 8))\n",
      "  Downloading chainlit-1.3.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting unstructured[md] (from -r requirements.txt (line 10))\n",
      "  Downloading unstructured-0.16.5-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached SQLAlchemy-2.0.36-cp310-cp310-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached aiohttp-3.10.10-cp310-cp310-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain->-r requirements.txt (line 1))\n",
      "  Downloading langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain->-r requirements.txt (line 1))\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain->-r requirements.txt (line 1))\n",
      "  Downloading langsmith-0.1.142-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting requests<3,>=2 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached SQLAlchemy-2.0.35-cp310-cp310-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community->-r requirements.txt (line 2))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community->-r requirements.txt (line 2))\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community->-r requirements.txt (line 2))\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting click<9.0.0,>=8.1.7 (from llama-parse->-r requirements.txt (line 3))\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-core>=0.11.0 (from llama-parse->-r requirements.txt (line 3))\n",
      "  Downloading llama_index_core-0.11.22-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.20 (from fastembed->-r requirements.txt (line 4))\n",
      "  Using cached huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting loguru<0.8.0,>=0.7.2 (from fastembed->-r requirements.txt (line 4))\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting mmh3<5.0.0,>=4.1.0 (from fastembed->-r requirements.txt (line 4))\n",
      "  Using cached mmh3-4.1.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting onnx<2.0.0,>=1.15.0 (from fastembed->-r requirements.txt (line 4))\n",
      "  Downloading onnx-1.17.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "Collecting onnxruntime<2.0.0,>=1.17.0 (from fastembed->-r requirements.txt (line 4))\n",
      "  Downloading onnxruntime-1.20.0-cp310-cp310-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting pillow<11.0.0,>=10.3.0 (from fastembed->-r requirements.txt (line 4))\n",
      "  Using cached pillow-10.4.0-cp310-cp310-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed->-r requirements.txt (line 4))\n",
      "  Downloading py_rust_stemmers-0.1.3-cp310-none-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting tokenizers<1.0,>=0.15 (from fastembed->-r requirements.txt (line 4))\n",
      "  Using cached tokenizers-0.20.3-cp310-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting tqdm<5.0,>=4.66 (from fastembed->-r requirements.txt (line 4))\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting build>=1.0.3 (from chromadb->-r requirements.txt (line 5))\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb->-r requirements.txt (line 5))\n",
      "  Using cached chroma_hnswlib-0.7.6-cp310-cp310-win_amd64.whl.metadata (262 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb->-r requirements.txt (line 5))\n",
      "  Using cached fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb->-r requirements.txt (line 5))\n",
      "  Using cached posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\talinho\\onedrive - insper - institudo de ensino e pesquisa\\área de trabalho\\llamahackhaton\\matchwork\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 5)) (4.12.2)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_sdk-1.28.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb->-r requirements.txt (line 5))\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Collecting overrides>=7.3.1 (from chromadb->-r requirements.txt (line 5))\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb->-r requirements.txt (line 5))\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb->-r requirements.txt (line 5))\n",
      "  Downloading grpcio-1.67.1-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb->-r requirements.txt (line 5))\n",
      "  Using cached bcrypt-4.2.0-cp39-abi3-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb->-r requirements.txt (line 5))\n",
      "  Downloading typer-0.13.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb->-r requirements.txt (line 5))\n",
      "  Using cached kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb->-r requirements.txt (line 5))\n",
      "  Downloading orjson-3.10.11-cp310-none-win_amd64.whl.metadata (52 kB)\n",
      "Collecting httpx>=0.27.0 (from chromadb->-r requirements.txt (line 5))\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting rich>=10.11.0 (from chromadb->-r requirements.txt (line 5))\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain-groq->-r requirements.txt (line 7))\n",
      "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiofiles<24.0.0,>=23.1.0 (from chainlit->-r requirements.txt (line 8))\n",
      "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting asyncer<0.0.8,>=0.0.7 (from chainlit->-r requirements.txt (line 8))\n",
      "  Downloading asyncer-0.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from chainlit->-r requirements.txt (line 8))\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting lazify<0.5.0,>=0.4.0 (from chainlit->-r requirements.txt (line 8))\n",
      "  Downloading Lazify-0.4.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting literalai==0.0.623 (from chainlit->-r requirements.txt (line 8))\n",
      "  Downloading literalai-0.0.623.tar.gz (57 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in c:\\users\\talinho\\onedrive - insper - institudo de ensino e pesquisa\\área de trabalho\\llamahackhaton\\matchwork\\.venv\\lib\\site-packages (from chainlit->-r requirements.txt (line 8)) (1.6.0)\n",
      "Collecting packaging<24.0,>=23.1 (from chainlit->-r requirements.txt (line 8))\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pyjwt<3.0.0,>=2.8.0 (from chainlit->-r requirements.txt (line 8))\n",
      "  Using cached PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting python-multipart<0.0.10,>=0.0.9 (from chainlit->-r requirements.txt (line 8))\n",
      "  Using cached python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting python-socketio<6.0.0,>=5.11.0 (from chainlit->-r requirements.txt (line 8))\n",
      "  Downloading python_socketio-5.11.4-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting starlette<0.42.0,>=0.41.2 (from chainlit->-r requirements.txt (line 8))\n",
      "  Using cached starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting syncer<3.0.0,>=2.0.3 (from chainlit->-r requirements.txt (line 8))\n",
      "  Downloading syncer-2.0.3.tar.gz (11 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tomli<3.0.0,>=2.0.1 (from chainlit->-r requirements.txt (line 8))\n",
      "  Using cached tomli-2.0.2-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting uptrace<2.0.0,>=1.22.0 (from chainlit->-r requirements.txt (line 8))\n",
      "  Downloading uptrace-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 5))\n",
      "  Downloading uvicorn-0.25.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting watchfiles<0.21.0,>=0.20.0 (from chainlit->-r requirements.txt (line 8))\n",
      "  Downloading watchfiles-0.20.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting chevron>=0.14.0 (from literalai==0.0.623->chainlit->-r requirements.txt (line 8))\n",
      "  Downloading chevron-0.14.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting chardet (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting python-magic (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached lxml-5.3.0-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting nltk (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting beautifulsoup4 (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting emoji (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-iso639 (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Downloading python_iso639-2024.10.22-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Collecting rapidfuzz (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Downloading rapidfuzz-3.10.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting unstructured-client (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Downloading unstructured_client-0.27.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting wrapt (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\talinho\\onedrive - insper - institudo de ensino e pesquisa\\área de trabalho\\llamahackhaton\\matchwork\\.venv\\lib\\site-packages (from unstructured[md]->-r requirements.txt (line 10)) (6.1.0)\n",
      "Collecting python-oxmsg (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting markdown (from unstructured[md]->-r requirements.txt (line 10))\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached frozenlist-1.5.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached multidict-6.1.0-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached yarl-1.17.1-cp310-cp310-win_amd64.whl.metadata (66 kB)\n",
      "Collecting anyio<5.0,>=3.4.0 (from asyncer<0.0.8,>=0.0.7->chainlit->-r requirements.txt (line 8))\n",
      "  Using cached anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\talinho\\onedrive - insper - institudo de ensino e pesquisa\\área de trabalho\\llamahackhaton\\matchwork\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 5)) (0.4.6)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 2))\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 2))\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting distro<2,>=1.7.0 (from groq<1,>=0.4.1->langchain-groq->-r requirements.txt (line 7))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting sniffio (from groq<1,>=0.4.1->langchain-groq->-r requirements.txt (line 7))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting certifi (from httpx>=0.27.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.27.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.20->fastembed->-r requirements.txt (line 4))\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.20->fastembed->-r requirements.txt (line 4))\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\talinho\\onedrive - insper - institudo de ensino e pesquisa\\área de trabalho\\llamahackhaton\\matchwork\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\talinho\\onedrive - insper - institudo de ensino e pesquisa\\área de trabalho\\llamahackhaton\\matchwork\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5))\n",
      "  Downloading google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting urllib3>=1.24.2 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.15->langchain->-r requirements.txt (line 1))\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 1))\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core>=0.11.0->llama-parse->-r requirements.txt (line 3))\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core>=0.11.0->llama-parse->-r requirements.txt (line 3))\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting networkx>=3.0 (from llama-index-core>=0.11.0->llama-parse->-r requirements.txt (line 3))\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core>=0.11.0->llama-parse->-r requirements.txt (line 3))\n",
      "  Using cached tiktoken-0.8.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru<0.8.0,>=0.7.2->fastembed->-r requirements.txt (line 4))\n",
      "  Downloading win32_setctime-1.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk->unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk->unstructured[md]->-r requirements.txt (line 10))\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Collecting protobuf>=3.20.2 (from onnx<2.0.0,>=1.15.0->fastembed->-r requirements.txt (line 4))\n",
      "  Using cached protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting coloredlogs (from onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4))\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4))\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting sympy (from onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4))\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 5))\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 5))\n",
      "  Downloading opentelemetry_util_http-0.49b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 1))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 1))\n",
      "  Using cached pydantic_core-2.23.4-cp310-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting bidict>=0.21.0 (from python-socketio<6.0.0,>=5.11.0->chainlit->-r requirements.txt (line 8))\n",
      "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting python-engineio>=4.8.0 (from python-socketio<6.0.0,>=5.11.0->chainlit->-r requirements.txt (line 8))\n",
      "  Downloading python_engineio-4.10.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain->-r requirements.txt (line 1))\n",
      "  Using cached charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl.metadata (34 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\talinho\\onedrive - insper - institudo de ensino e pesquisa\\área de trabalho\\llamahackhaton\\matchwork\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 5)) (2.18.0)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 1))\n",
      "  Using cached greenlet-3.1.1-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp~=1.27 (from uptrace<2.0.0,>=1.22.0->chainlit->-r requirements.txt (line 8))\n",
      "  Downloading opentelemetry_exporter_otlp-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is looking at multiple versions of uvicorn[standard] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting uvicorn[standard]>=0.18.3 (from chromadb->-r requirements.txt (line 5))\n",
      "  Using cached uvicorn-0.31.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Using cached uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Using cached uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading uvicorn-0.30.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Using cached uvicorn-0.30.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading uvicorn-0.30.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading uvicorn-0.30.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "INFO: pip is still looking at multiple versions of uvicorn[standard] to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Downloading uvicorn-0.30.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Downloading uvicorn-0.28.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Downloading uvicorn-0.28.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading uvicorn-0.27.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Downloading uvicorn-0.27.0.post1-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Downloading uvicorn-0.27.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Downloading uvicorn-0.26.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached httptools-0.6.4-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 5))\n",
      "  Downloading websockets-14.0-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting webencodings (from html5lib->unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting olefile (from python-oxmsg->unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured[md]->-r requirements.txt (line 10))\n",
      "  Downloading cryptography-43.0.3-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting eval-type-backport<0.3.0,>=0.2.0 (from unstructured-client->unstructured[md]->-r requirements.txt (line 10))\n",
      "  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jsonpath-python<2.0.0,>=1.0.6 (from unstructured-client->unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting python-dateutil>=2.5.3 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5))\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\talinho\\onedrive - insper - institudo de ensino e pesquisa\\área de trabalho\\llamahackhaton\\matchwork\\.venv\\lib\\site-packages (from anyio<5.0,>=3.4.0->asyncer<0.0.8,>=0.0.7->chainlit->-r requirements.txt (line 8)) (1.2.2)\n",
      "Collecting cffi>=1.12 (from cryptography>=3.1->unstructured-client->unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached cffi-1.17.1-cp310-cp310-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain->-r requirements.txt (line 1))\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.28.1 (from opentelemetry-exporter-otlp~=1.27->uptrace<2.0.0,>=1.22.0->chainlit->-r requirements.txt (line 8))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.8.0->python-socketio<6.0.0,>=5.11.0->chainlit->-r requirements.txt (line 8))\n",
      "  Downloading simple_websocket-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 2))\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached propcache-0.2.0-cp310-cp310-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4))\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured[md]->-r requirements.txt (line 10))\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 4))\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 5))\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio<6.0.0,>=5.11.0->chainlit->-r requirements.txt (line 8))\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Downloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading langchain_community-0.3.5-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 17.2 MB/s eta 0:00:00\n",
      "Downloading llama_parse-0.5.13-py3-none-any.whl (13 kB)\n",
      "Downloading fastembed-0.4.1-py3-none-any.whl (65 kB)\n",
      "Downloading chromadb-0.5.18-py3-none-any.whl (615 kB)\n",
      "   ---------------------------------------- 0.0/615.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 615.5/615.5 kB 11.4 MB/s eta 0:00:00\n",
      "Using cached chroma_hnswlib-0.7.6-cp310-cp310-win_amd64.whl (150 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading langchain_groq-0.2.1-py3-none-any.whl (14 kB)\n",
      "Downloading chainlit-1.3.2-py3-none-any.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 20.0 MB/s eta 0:00:00\n",
      "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiohttp-3.10.10-cp310-cp310-win_amd64.whl (381 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading asyncer-0.0.7-py3-none-any.whl (8.5 kB)\n",
      "Using cached bcrypt-4.2.0-cp39-abi3-win_amd64.whl (151 kB)\n",
      "Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
      "Downloading grpcio-1.67.1-cp310-cp310-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.4/4.4 MB 23.9 MB/s eta 0:00:00\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Using cached kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "Downloading langchain_core-0.3.15-py3-none-any.whl (408 kB)\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.142-py3-none-any.whl (306 kB)\n",
      "Downloading Lazify-0.4.0-py2.py3-none-any.whl (3.1 kB)\n",
      "Downloading llama_index_core-0.11.22-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 14.0 MB/s eta 0:00:00\n",
      "Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "Using cached mmh3-4.1.0-cp310-cp310-win_amd64.whl (31 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Downloading onnx-1.17.0-cp310-cp310-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 7.1/14.5 MB 36.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.5 MB 31.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.5 MB 30.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 20.3 MB/s eta 0:00:00\n",
      "Downloading onnxruntime-1.20.0-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 3.1/11.3 MB 16.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.9/11.3 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 18.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 18.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 12.6 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.28.1-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.28.1-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl (159 kB)\n",
      "Downloading opentelemetry_util_http-0.49b1-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.28.1-py3-none-any.whl (118 kB)\n",
      "Downloading orjson-3.10.11-cp310-none-win_amd64.whl (136 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached pillow-10.4.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Using cached posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading py_rust_stemmers-0.1.3-cp310-none-win_amd64.whl (208 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Using cached pydantic_core-2.23.4-cp310-none-win_amd64.whl (1.9 MB)\n",
      "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Using cached PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
      "Using cached python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading python_socketio-5.11.4-py3-none-any.whl (76 kB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached SQLAlchemy-2.0.35-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "Using cached starlette-0.41.2-py3-none-any.whl (73 kB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached tokenizers-0.20.3-cp310-none-win_amd64.whl (2.4 MB)\n",
      "Using cached tomli-2.0.2-py3-none-any.whl (13 kB)\n",
      "Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Downloading typer-0.13.0-py3-none-any.whl (44 kB)\n",
      "Downloading uptrace-1.27.0-py3-none-any.whl (8.6 kB)\n",
      "Downloading uvicorn-0.25.0-py3-none-any.whl (60 kB)\n",
      "Downloading watchfiles-0.20.0-cp37-abi3-win_amd64.whl (276 kB)\n",
      "Using cached wrapt-1.16.0-cp310-cp310-win_amd64.whl (37 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached emoji-2.14.0-py3-none-any.whl (586 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Using cached lxml-5.3.0-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading python_iso639-2024.10.22-py3-none-any.whl (274 kB)\n",
      "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Using cached python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.10.1-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 12.2 MB/s eta 0:00:00\n",
      "Downloading unstructured-0.16.5-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading unstructured_client-0.27.0-py3-none-any.whl (59 kB)\n",
      "Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Downloading chevron-0.14.0-py3-none-any.whl (11 kB)\n",
      "Downloading cryptography-43.0.3-cp39-abi3-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.8/3.1 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.1/3.1 MB 7.2 MB/s eta 0:00:00\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached frozenlist-1.5.0-cp310-cp310-win_amd64.whl (51 kB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Using cached greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached multidict-6.1.0-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading opentelemetry_exporter_otlp-1.28.1-py3-none-any.whl (7.0 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.28.1-py3-none-any.whl (17 kB)\n",
      "Using cached protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Using cached pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Downloading python_engineio-4.10.1-py3-none-any.whl (57 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached tiktoken-0.8.0-cp310-cp310-win_amd64.whl (884 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-14.0-cp310-cp310-win_amd64.whl (162 kB)\n",
      "Downloading win32_setctime-1.1.0-py3-none-any.whl (3.6 kB)\n",
      "Using cached yarl-1.17.1-cp310-cp310-win_amd64.whl (89 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached cffi-1.17.1-cp310-cp310-win_amd64.whl (181 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached propcache-0.2.0-cp310-cp310-win_amd64.whl (44 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading simple_websocket-1.1.0-py3-none-any.whl (13 kB)\n",
      "Using cached zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: literalai, syncer\n",
      "  Building wheel for literalai (pyproject.toml): started\n",
      "  Building wheel for literalai (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for literalai: filename=literalai-0.0.623-py3-none-any.whl size=74012 sha256=b758f21794cae1728d12795185bb53aef0385f596391b06f00b0dae8d020003f\n",
      "  Stored in directory: c:\\users\\talinho\\appdata\\local\\pip\\cache\\wheels\\54\\6a\\4a\\b7e8718e50c9722d0d775f09a7e525bed7759407d51324287d\n",
      "  Building wheel for syncer (pyproject.toml): started\n",
      "  Building wheel for syncer (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for syncer: filename=syncer-2.0.3-py2.py3-none-any.whl size=3454 sha256=9f8b5f9f19fb7c63813ff6b2ce455ba17456bdd325897ff03cc40f7e3febf950\n",
      "  Stored in directory: c:\\users\\talinho\\appdata\\local\\pip\\cache\\wheels\\09\\e4\\36\\bcaad665bcc2b672888ff2df1a5a1dc638378d8765055313cd\n",
      "Successfully built literalai syncer\n",
      "Installing collected packages: webencodings, syncer, pypika, py-rust-stemmers, mpmath, monotonic, mmh3, lazify, flatbuffers, filetype, durationpy, dirtyjson, chevron, zipp, wrapt, win32-setctime, websockets, websocket-client, urllib3, tqdm, tomli, tenacity, sympy, soupsieve, sniffio, shellingham, regex, rapidfuzz, PyYAML, python-multipart, python-magic, python-iso639, python-dotenv, python-dateutil, pyreadline3, pyproject_hooks, pypdf, pyjwt, pydantic-core, pycparser, pyasn1, protobuf, propcache, pillow, packaging, overrides, orjson, opentelemetry-util-http, olefile, oauthlib, numpy, networkx, mypy-extensions, multidict, mdurl, markdown, lxml, langdetect, jsonpointer, jsonpath-python, joblib, importlib-resources, idna, httpx-sse, httptools, html5lib, h11, grpcio, greenlet, fsspec, frozenlist, filelock, eval-type-backport, emoji, distro, click, charset-normalizer, chardet, certifi, cachetools, bidict, bcrypt, backoff, attrs, async-timeout, asgiref, annotated-types, aiohappyeyeballs, aiofiles, yarl, wsproto, uvicorn, typing-inspect, SQLAlchemy, rsa, requests, python-oxmsg, pydantic, pyasn1-modules, opentelemetry-proto, onnx, nltk, marshmallow, markdown-it-py, loguru, jsonpatch, importlib-metadata, humanfriendly, httpcore, googleapis-common-protos, deprecated, chroma-hnswlib, cffi, build, beautifulsoup4, anyio, aiosignal, watchfiles, tiktoken, starlette, simple-websocket, rich, requests-toolbelt, requests-oauthlib, pydantic-settings, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, huggingface-hub, httpx, google-auth, dataclasses-json, cryptography, coloredlogs, asyncer, aiohttp, unstructured-client, typer, tokenizers, python-engineio, opentelemetry-semantic-conventions, onnxruntime, llama-index-core, literalai, langsmith, kubernetes, groq, fastapi, unstructured, python-socketio, opentelemetry-sdk, opentelemetry-instrumentation, llama-parse, langchain-core, fastembed, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-groq, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp, langchain, uptrace, langchain-community, chromadb, chainlit\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.35 aiofiles-23.2.1 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.6.2.post1 asgiref-3.8.1 async-timeout-4.0.3 asyncer-0.0.7 attrs-24.2.0 backoff-2.2.1 bcrypt-4.2.0 beautifulsoup4-4.12.3 bidict-0.23.1 build-1.2.2.post1 cachetools-5.5.0 certifi-2024.8.30 cffi-1.17.1 chainlit-1.3.2 chardet-5.2.0 charset-normalizer-3.4.0 chevron-0.14.0 chroma-hnswlib-0.7.6 chromadb-0.5.18 click-8.1.7 coloredlogs-15.0.1 cryptography-43.0.3 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 durationpy-0.9 emoji-2.14.0 eval-type-backport-0.2.0 fastapi-0.115.4 fastembed-0.4.1 filelock-3.16.1 filetype-1.2.0 flatbuffers-24.3.25 frozenlist-1.5.0 fsspec-2024.10.0 google-auth-2.36.0 googleapis-common-protos-1.65.0 greenlet-3.1.1 groq-0.11.0 grpcio-1.67.1 h11-0.14.0 html5lib-1.1 httpcore-1.0.6 httptools-0.6.4 httpx-0.27.2 httpx-sse-0.4.0 huggingface-hub-0.26.2 humanfriendly-10.0 idna-3.10 importlib-metadata-8.5.0 importlib-resources-6.4.5 joblib-1.4.2 jsonpatch-1.33 jsonpath-python-1.0.6 jsonpointer-3.0.0 kubernetes-31.0.0 langchain-0.3.7 langchain-community-0.3.5 langchain-core-0.3.15 langchain-groq-0.2.1 langchain-text-splitters-0.3.2 langdetect-1.0.9 langsmith-0.1.142 lazify-0.4.0 literalai-0.0.623 llama-index-core-0.11.22 llama-parse-0.5.13 loguru-0.7.2 lxml-5.3.0 markdown-3.7 markdown-it-py-3.0.0 marshmallow-3.23.1 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 multidict-6.1.0 mypy-extensions-1.0.0 networkx-3.4.2 nltk-3.9.1 numpy-1.26.4 oauthlib-3.2.2 olefile-0.47 onnx-1.17.0 onnxruntime-1.20.0 opentelemetry-api-1.28.1 opentelemetry-exporter-otlp-1.28.1 opentelemetry-exporter-otlp-proto-common-1.28.1 opentelemetry-exporter-otlp-proto-grpc-1.28.1 opentelemetry-exporter-otlp-proto-http-1.28.1 opentelemetry-instrumentation-0.49b1 opentelemetry-instrumentation-asgi-0.49b1 opentelemetry-instrumentation-fastapi-0.49b1 opentelemetry-proto-1.28.1 opentelemetry-sdk-1.28.1 opentelemetry-semantic-conventions-0.49b1 opentelemetry-util-http-0.49b1 orjson-3.10.11 overrides-7.7.0 packaging-23.2 pillow-10.4.0 posthog-3.7.0 propcache-0.2.0 protobuf-5.28.3 py-rust-stemmers-0.1.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycparser-2.22 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.6.1 pyjwt-2.9.0 pypdf-5.1.0 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 python-dateutil-2.8.2 python-dotenv-1.0.1 python-engineio-4.10.1 python-iso639-2024.10.22 python-magic-0.4.27 python-multipart-0.0.9 python-oxmsg-0.0.1 python-socketio-5.11.4 rapidfuzz-3.10.1 regex-2024.11.6 requests-2.32.3 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-13.9.4 rsa-4.9 shellingham-1.5.4 simple-websocket-1.1.0 sniffio-1.3.1 soupsieve-2.6 starlette-0.41.2 sympy-1.13.3 syncer-2.0.3 tenacity-8.5.0 tiktoken-0.8.0 tokenizers-0.20.3 tomli-2.0.2 tqdm-4.67.0 typer-0.13.0 typing-inspect-0.9.0 unstructured-0.16.5 unstructured-client-0.27.0 uptrace-1.27.0 urllib3-2.2.3 uvicorn-0.25.0 watchfiles-0.20.0 webencodings-0.5.1 websocket-client-1.8.0 websockets-14.0 win32-setctime-1.1.0 wrapt-1.16.0 wsproto-1.2.0 yarl-1.17.1 zipp-3.20.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### LLAMAPARSE #####\n",
    "from llama_parse import LlamaParse\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "from groq import Groq\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "#\n",
    "import joblib\n",
    "import os\n",
    "import nest_asyncio  # noqa: E402\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsingInstructionsInterviewer = \"\"\"\n",
    "O documento a seguir é um currículode um possível candidato em busca de vagas.\n",
    "No documento, haverá uma seção contendo as Experiências do candidato e outra contendo as Atividades Extracurriculares dele.\n",
    "Extraia o que conseguir dessas partes e também as informações pessoais do candidato.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id bbf35d51-5c73-4a67-99f0-693fb5ac82b8\n"
     ]
    }
   ],
   "source": [
    "llamaparse = LlamaParse(parsing_instruction=parsingInstructionsInterviewer, result_type=\"markdown\")\n",
    "parsed_result = llamaparse.get_json_result(\"CVs\\CV Tales Ivalque.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pages': [{'page': 1,\n",
       "    'text': 'TALES IVALQUE TAVEIRA DE FREITAS\\nBrasileiro, 22 anos\\n+55 11 98584 0164\\ntalesitf@al.insper.edu.br\\n\\nOBJETIVO\\n                           Experiências na área de Dados, Pesquisa e LLMs\\n\\nFORMAÇÃO\\nAgo/21 a Set/26            Insper – Triple Accredited Business School (AACSB, AMBA, EQUIS)\\n                           Bacharelado em Engenharia de Computação\\n                           Desempenho acima de 80% nos trabalhos e provas\\nFev/18 a Jul/21            Colégio Farias Brito – Fortaleza/CE\\n                            3º ano Ensino Médio +Curso preparatório ITA/IME;\\n                            Competência em cálculo diferencial, matemática e física avançada\\n\\nJan/16 a Dez/17            Colégio Módulo – Juazeiro do Norte/CE\\n                           Ensino Médio\\n\\nEXPERIENCIA\\nOut/21 a Dez/21            Insper --Triple Accredited Business School (AACSB, AMBA, EQUIS)\\n                           Desenvolvedor estagiário\\n                           Transferência de formato de programação de um dos servidores de ensino da Instituição.\\n\\nJul/22 a Ago/22            Hyperlocal\\n                           Estagiário de Produtos\\n                           Atuação no planejamento e documentação da API dos principais produtos da empresa\\nAgo/22 -                   Insper\\n                           NINJA de Ciências dos Dados\\n                           Auxílio aos professores das disciplinas na correção de trabalhos e auxílio geral aos alunos da\\n                           matéria.\\n\\nIDIOMAS\\n                           Inglês avançado, Espanhol básico\\n\\nINFORMÁTICA\\n                           Domínio do Pacote Office, com Excel intermediário\\n\\n                           Programação: Python, Arduino, C/C++/C#, Java, Dart\\n\\nEXTRACURRICULAR\\nNov/15                     Porta-voz das equipes brasileiras em competição olímpica internacional\\n                           Tradução em tempo real dos discursos dos representantes das várias equipes participantes.\\nOut/22 -                   Aulas GAS\\n                           Professor de revisão de disciplinas pré Pis e PFs\\n\\nFev/14 a Dez/18             Acervo de conquistas em competições acadêmica-científicas\\n                            Medalhas de Ouro e prata consecutivas em Olimpíadas de Programação, Robótica, Física,\\n                            Matemática e Química',\n",
       "    'md': '**Informações Pessoais:**\\n- Nome: Tales Ivalque Taveira de Freitas\\n- Nacionalidade: Brasileiro\\n- Idade: 22 anos\\n- Telefone: +55 11 98584 0164\\n- E-mail: talesitf@al.insper.edu.br\\n\\n**Objetivo:**\\n- Experiências na área de Dados, Pesquisa e LLMs\\n\\n**Formação:**\\n- **Insper – Triple Accredited Business School (AACSB, AMBA, EQUIS)**\\n- Bacharelado em Engenharia de Computação\\n- Período: Ago/21 a Set/26\\n- Desempenho: Acima de 80% nos trabalhos e provas\\n\\n- **Colégio Farias Brito – Fortaleza/CE**\\n- 3º ano Ensino Médio + Curso preparatório ITA/IME\\n- Período: Fev/18 a Jul/21\\n- Competência em cálculo diferencial, matemática e física avançada\\n\\n- **Colégio Módulo – Juazeiro do Norte/CE**\\n- Ensino Médio\\n- Período: Jan/16 a Dez/17\\n\\n**Experiências:**\\n- **Insper – Triple Accredited Business School (AACSB, AMBA, EQUIS)**\\n- Cargo: Desenvolvedor estagiário\\n- Período: Out/21 a Dez/21\\n- Atividade: Transferência de formato de programação de um dos servidores de ensino da Instituição.\\n\\n- **Hyperlocal**\\n- Cargo: Estagiário de Produtos\\n- Período: Jul/22 a Ago/22\\n- Atividade: Atuação no planejamento e documentação da API dos principais produtos da empresa.\\n\\n- **Insper**\\n- Cargo: NINJA de Ciências dos Dados\\n- Período: Ago/22 - Presente\\n- Atividade: Auxílio aos professores das disciplinas na correção de trabalhos e auxílio geral aos alunos da matéria.\\n\\n**Idiomas:**\\n- Inglês: Avançado\\n- Espanhol: Básico\\n\\n**Informática:**\\n- Domínio do Pacote Office (Excel intermediário)\\n- Programação: Python, Arduino, C/C++/C#, Java, Dart\\n\\n**Atividades Extracurriculares:**\\n- **Nov/15**: Porta-voz das equipes brasileiras em competição olímpica internacional, realizando tradução em tempo real dos discursos dos representantes das várias equipes participantes.\\n- **Out/22 - Presente**: Aulas GAS, atuando como professor de revisão de disciplinas pré Pis e PFs.\\n- **Fev/14 a Dez/18**: Acervo de conquistas em competições acadêmica-científicas, com medalhas de ouro e prata consecutivas em Olimpíadas de Programação, Robótica, Física, Matemática e Química.',\n",
       "    'images': [],\n",
       "    'items': [{'type': 'text',\n",
       "      'value': '**Informações Pessoais:**\\n- Nome: Tales Ivalque Taveira de Freitas\\n- Nacionalidade: Brasileiro\\n- Idade: 22 anos\\n- Telefone: +55 11 98584 0164\\n- E-mail: talesitf@al.insper.edu.br\\n\\n**Objetivo:**\\n- Experiências na área de Dados, Pesquisa e LLMs\\n\\n**Formação:**\\n- **Insper – Triple Accredited Business School (AACSB, AMBA, EQUIS)**\\n- Bacharelado em Engenharia de Computação\\n- Período: Ago/21 a Set/26\\n- Desempenho: Acima de 80% nos trabalhos e provas\\n\\n- **Colégio Farias Brito – Fortaleza/CE**\\n- 3º ano Ensino Médio + Curso preparatório ITA/IME\\n- Período: Fev/18 a Jul/21\\n- Competência em cálculo diferencial, matemática e física avançada\\n\\n- **Colégio Módulo – Juazeiro do Norte/CE**\\n- Ensino Médio\\n- Período: Jan/16 a Dez/17\\n\\n**Experiências:**\\n- **Insper – Triple Accredited Business School (AACSB, AMBA, EQUIS)**\\n- Cargo: Desenvolvedor estagiário\\n- Período: Out/21 a Dez/21\\n- Atividade: Transferência de formato de programação de um dos servidores de ensino da Instituição.\\n\\n- **Hyperlocal**\\n- Cargo: Estagiário de Produtos\\n- Período: Jul/22 a Ago/22\\n- Atividade: Atuação no planejamento e documentação da API dos principais produtos da empresa.\\n\\n- **Insper**\\n- Cargo: NINJA de Ciências dos Dados\\n- Período: Ago/22 - Presente\\n- Atividade: Auxílio aos professores das disciplinas na correção de trabalhos e auxílio geral aos alunos da matéria.\\n\\n**Idiomas:**\\n- Inglês: Avançado\\n- Espanhol: Básico\\n\\n**Informática:**\\n- Domínio do Pacote Office (Excel intermediário)\\n- Programação: Python, Arduino, C/C++/C#, Java, Dart\\n\\n**Atividades Extracurriculares:**\\n- **Nov/15**: Porta-voz das equipes brasileiras em competição olímpica internacional, realizando tradução em tempo real dos discursos dos representantes das várias equipes participantes.\\n- **Out/22 - Presente**: Aulas GAS, atuando como professor de revisão de disciplinas pré Pis e PFs.\\n- **Fev/14 a Dez/18**: Acervo de conquistas em competições acadêmica-científicas, com medalhas de ouro e prata consecutivas em Olimpíadas de Programação, Robótica, Física, Matemática e Química.',\n",
       "      'md': '**Informações Pessoais:**\\n- Nome: Tales Ivalque Taveira de Freitas\\n- Nacionalidade: Brasileiro\\n- Idade: 22 anos\\n- Telefone: +55 11 98584 0164\\n- E-mail: talesitf@al.insper.edu.br\\n\\n**Objetivo:**\\n- Experiências na área de Dados, Pesquisa e LLMs\\n\\n**Formação:**\\n- **Insper – Triple Accredited Business School (AACSB, AMBA, EQUIS)**\\n- Bacharelado em Engenharia de Computação\\n- Período: Ago/21 a Set/26\\n- Desempenho: Acima de 80% nos trabalhos e provas\\n\\n- **Colégio Farias Brito – Fortaleza/CE**\\n- 3º ano Ensino Médio + Curso preparatório ITA/IME\\n- Período: Fev/18 a Jul/21\\n- Competência em cálculo diferencial, matemática e física avançada\\n\\n- **Colégio Módulo – Juazeiro do Norte/CE**\\n- Ensino Médio\\n- Período: Jan/16 a Dez/17\\n\\n**Experiências:**\\n- **Insper – Triple Accredited Business School (AACSB, AMBA, EQUIS)**\\n- Cargo: Desenvolvedor estagiário\\n- Período: Out/21 a Dez/21\\n- Atividade: Transferência de formato de programação de um dos servidores de ensino da Instituição.\\n\\n- **Hyperlocal**\\n- Cargo: Estagiário de Produtos\\n- Período: Jul/22 a Ago/22\\n- Atividade: Atuação no planejamento e documentação da API dos principais produtos da empresa.\\n\\n- **Insper**\\n- Cargo: NINJA de Ciências dos Dados\\n- Período: Ago/22 - Presente\\n- Atividade: Auxílio aos professores das disciplinas na correção de trabalhos e auxílio geral aos alunos da matéria.\\n\\n**Idiomas:**\\n- Inglês: Avançado\\n- Espanhol: Básico\\n\\n**Informática:**\\n- Domínio do Pacote Office (Excel intermediário)\\n- Programação: Python, Arduino, C/C++/C#, Java, Dart\\n\\n**Atividades Extracurriculares:**\\n- **Nov/15**: Porta-voz das equipes brasileiras em competição olímpica internacional, realizando tradução em tempo real dos discursos dos representantes das várias equipes participantes.\\n- **Out/22 - Presente**: Aulas GAS, atuando como professor de revisão de disciplinas pré Pis e PFs.\\n- **Fev/14 a Dez/18**: Acervo de conquistas em competições acadêmica-científicas, com medalhas de ouro e prata consecutivas em Olimpíadas de Programação, Robótica, Física, Matemática e Química.',\n",
       "      'bBox': {'x': 36, 'y': 51.92, 'w': 410.68, 'h': 15.96}}],\n",
       "    'status': 'OK',\n",
       "    'links': []}],\n",
       "  'job_metadata': {'credits_used': 205.0,\n",
       "   'job_credits_usage': 0,\n",
       "   'job_pages': 0,\n",
       "   'job_is_cache_hit': True},\n",
       "  'job_id': 'bbf35d51-5c73-4a67-99f0-693fb5ac82b8',\n",
       "  'file_path': 'CVs\\\\CV Tales Ivalque.pdf'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Informações Pessoais:**\n",
       "- Nome: Tales Ivalque Taveira de Freitas\n",
       "- Nacionalidade: Brasileiro\n",
       "- Idade: 22 anos\n",
       "- Telefone: +55 11 98584 0164\n",
       "- E-mail: talesitf@al.insper.edu.br\n",
       "\n",
       "**Objetivo:**\n",
       "- Experiências na área de Dados, Pesquisa e LLMs\n",
       "\n",
       "**Formação:**\n",
       "- **Insper – Triple Accredited Business School (AACSB, AMBA, EQUIS)**\n",
       "- Bacharelado em Engenharia de Computação\n",
       "- Período: Ago/21 a Set/26\n",
       "- Desempenho: Acima de 80% nos trabalhos e provas\n",
       "\n",
       "- **Colégio Farias Brito – Fortaleza/CE**\n",
       "- 3º ano Ensino Médio + Curso preparatório ITA/IME\n",
       "- Período: Fev/18 a Jul/21\n",
       "- Competência em cálculo diferencial, matemática e física avançada\n",
       "\n",
       "- **Colégio Módulo – Juazeiro do Norte/CE**\n",
       "- Ensino Médio\n",
       "- Período: Jan/16 a Dez/17\n",
       "\n",
       "**Experiências:**\n",
       "- **Insper – Triple Accredited Business School (AACSB, AMBA, EQUIS)**\n",
       "- Cargo: Desenvolvedor estagiário\n",
       "- Período: Out/21 a Dez/21\n",
       "- Atividade: Transferência de formato de programação de um dos servidores de ensino da Instituição.\n",
       "\n",
       "- **Hyperlocal**\n",
       "- Cargo: Estagiário de Produtos\n",
       "- Período: Jul/22 a Ago/22\n",
       "- Atividade: Atuação no planejamento e documentação da API dos principais produtos da empresa.\n",
       "\n",
       "- **Insper**\n",
       "- Cargo: NINJA de Ciências dos Dados\n",
       "- Período: Ago/22 - Presente\n",
       "- Atividade: Auxílio aos professores das disciplinas na correção de trabalhos e auxílio geral aos alunos da matéria.\n",
       "\n",
       "**Idiomas:**\n",
       "- Inglês: Avançado\n",
       "- Espanhol: Básico\n",
       "\n",
       "**Informática:**\n",
       "- Domínio do Pacote Office (Excel intermediário)\n",
       "- Programação: Python, Arduino, C/C++/C#, Java, Dart\n",
       "\n",
       "**Atividades Extracurriculares:**\n",
       "- **Nov/15**: Porta-voz das equipes brasileiras em competição olímpica internacional, realizando tradução em tempo real dos discursos dos representantes das várias equipes participantes.\n",
       "- **Out/22 - Presente**: Aulas GAS, atuando como professor de revisão de disciplinas pré Pis e PFs.\n",
       "- **Fev/14 a Dez/18**: Acervo de conquistas em competições acadêmica-científicas, com medalhas de ouro e prata consecutivas em Olimpíadas de Programação, Robótica, Física, Matemática e Química."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "display(Markdown(parsed_result[0]['pages'][0]['md']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatGroq(temperature=0, model_name=\"llama-3.1-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Activity(BaseModel):\n",
    "    \"\"\"\n",
    "    A detailed description of an activity and the role of a candidate in them.\n",
    "    \"\"\"\n",
    "    description: str = Field(description = \"What is the activity\")\n",
    "    role: str = Field(description=\"Role the candidate served on the acitivity\")\n",
    "\n",
    "class Topics(BaseModel):\n",
    "    \"\"\"\n",
    "    Lists of maybe important topics for a candidate\n",
    "    \"\"\"\n",
    "    expiriences: List[Activity]\n",
    "    activities: List[Activity]\n",
    "    projects: List[Activity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topics(expiriences=[Activity(description='Desenvolvedor estagiário na Insper – Triple Accredited Business School (AACSB, AMBA, EQUIS)', role='Desenvolvedor estagiário'), Activity(description='Estagiário de Produtos na Hyperlocal', role='Estagiário de Produtos'), Activity(description='NINJA de Ciências dos Dados na Insper', role='NINJA de Ciências dos Dados')], activities=[Activity(description='Porta-voz das equipes brasileiras em competição olímpica internacional, realizando tradução em tempo real dos discursos dos representantes das várias equipes participantes.', role='Porta-voz'), Activity(description='Aulas GAS, atuando como professor de revisão de disciplinas pré Pis e PFs.', role='Professor'), Activity(description='Acervo de conquistas em competições acadêmica-científicas, com medalhas de ouro e prata consecutivas em Olimpíadas de Programação, Robótica, Física, Matemática e Química.', role='Competidor')], projects=[Activity(description='Transferência de formato de programação de um dos servidores de ensino da Instituição.', role='Desenvolvedor estagiário'), Activity(description='Atuação no planejamento e documentação da API dos principais produtos da empresa.', role='Estagiário de Produtos'), Activity(description='Auxílio aos professores das disciplinas na correção de trabalhos e auxílio geral aos alunos da matéria.', role='NINJA de Ciências dos Dados')])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that hepls identify a candidate's experience, activities and projects based on the following markdown text: {curriculum}. \",\n",
    "    ),\n",
    "    (\n",
    "        \"system\",\n",
    "        \"Here are the topics:\"\n",
    "    )\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "chat_model = chat_model.with_structured_output(Topics)\n",
    "\n",
    "chain_structured = prompt | chat_model\n",
    "response = chain_structured.invoke({\"curriculum\":parsed_result[0]['pages'][0]['md']})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Activity(description='Desenvolvedor estagiário na Insper – Triple Accredited Business School (AACSB, AMBA, EQUIS)', role='Desenvolvedor estagiário'),\n",
       " Activity(description='Estagiário de Produtos na Hyperlocal', role='Estagiário de Produtos'),\n",
       " Activity(description='NINJA de Ciências dos Dados na Insper', role='NINJA de Ciências dos Dados')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.expiriences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topics(expiriences=[], activities=[Activity(description='Team Lead for a group project at university', role='Team Lead'), Activity(description='Volunteer at a local animal shelter', role='Volunteer')], projects=[])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_questions = ChatGroq(temperature=0.3, model_name=\"llama-3.1-70b-versatile\")\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"You are a helpful assistant that works in the People Departament and must devise meaninful questions based on a candidate's experience, activities and projects.\n",
    "           Your main role here is to identify how the candidate responds to different forms of interations, the commitement of the candidate to the activity, and what motivated him for the activities.\n",
    "           You are to create 3 questions based on the following:\n",
    "           {activities}\n",
    "           {experiences}\n",
    "           {projects}\n",
    "\n",
    "           Remenber, choose questions for topics with the most importance based on leadership, independence, proactivity, personal relations and challenge overcoming.\n",
    "        \"\"\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "chain_structured = prompt | llm_questions\n",
    "\n",
    "activities = response.activities\n",
    "experiences = response.experiences\n",
    "projects = response.projects\n",
    "\n",
    "\n",
    "ai_msg = chain_structured.invoke({\n",
    "    \"activities\": activities,\n",
    "    \"experiences\": experiences,\n",
    "    \"projects\": projects\n",
    "})\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
